{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import AsyncHTMLSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilts\n",
    "import os\n",
    "import json\n",
    "def printSoupToHtml(soup):\n",
    "    #Creating a file if not exist\n",
    "    if not os.path.exists('soup.html'):\n",
    "        with open('soup.html', 'w', encoding='utf-8') as file:\n",
    "            file.write('')\n",
    "    with open('soup.html', 'w', encoding='utf-8') as file:\n",
    "        file.write(str(soup))\n",
    "    return True\n",
    "def printSoupToJson(soup):\n",
    "    #Creating a file if not exist\n",
    "    if not os.path.exists('soup.json'):\n",
    "        with open('soup.json', 'w', encoding='utf-8') as file:\n",
    "            file.write('')\n",
    "    with open('soup.json', 'w', encoding='utf-8') as file:\n",
    "        file.write(json.dumps(soup))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "async def scrapeAmazonSa(url):\n",
    "    asession = AsyncHTMLSession()\n",
    "    #attach random user agent and proxy\n",
    "    asession=AsyncHTMLSession(\n",
    "        mock_browser=True,\n",
    "    )\n",
    "    response = await asession.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    printSoupToHtml(soup)\n",
    "    #Data\n",
    "    price = soup.select_one('.aok-align-center span.a-price-whole').get_text().split(\".\")[0]\n",
    "    title = soup.select_one('span.product-title-word-break').get_text().strip()\n",
    "    rating = soup.select_one('#averageCustomerReviews_feature_div span.a-color-base').get_text().strip()\n",
    "    discription = soup.select_one('ul.a-spacing-mini').get_text().strip()\n",
    "    print (price, title, rating , discription)\n",
    "    return  price, title, rating , discription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "async def scrapeAmazonSa(url , attempt=0):\n",
    "    try:\n",
    "        if attempt >= 100:\n",
    "            # Max retry attempts reached, return empty result or handle accordingly\n",
    "            return {\"images\": []}\n",
    "\n",
    "        asession = AsyncHTMLSession(mock_browser=True)\n",
    "        response = await asession.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        result = soup.select(\"#imageBlock img\")\n",
    "        \n",
    "        for img in result:\n",
    "            if 'data-a-dynamic-image' in img.attrs:\n",
    "                dynamic_images = eval(img['data-a-dynamic-image'])\n",
    "                images=(list(dynamic_images.keys()))\n",
    "        item_data = {\n",
    "            \"images\": images\n",
    "        }\n",
    "        return item_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Retry recursively with incremented attempt count\n",
    "        print(f\"Error occurred on attempt {attempt + 1}: {e}\")\n",
    "        return await scrapeAmazonSa(url, attempt + 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred on attempt 1: local variable 'images' referenced before assignment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'images': ['https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX425_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX522_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX569_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX355_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX450_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX466_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/71vdMuZUW9L._AC_SX679_.jpg']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "import time\n",
    "url = 'https://www.amazon.sa/%D8%A7%D8%AA%D8%B4-%D8%A8%D9%8A-14-ek1001nx%D8%8C-%D8%AC%D9%8A%D8%AC%D8%A7%D8%A8%D8%A7%D9%8A%D8%AA%D8%8C-%D8%AA%D9%8A%D8%B1%D8%A7%D8%A8%D8%A7%D9%8A%D8%AA%D8%8C/dp/B0CM383CTZ/ref=sr_1_3?refinements=p_n_feature_fifteen_browse-bin%3A16969389031&s=electronics&sr=1-3'\n",
    "success = False\n",
    "await scrapeAmazonSa(url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
